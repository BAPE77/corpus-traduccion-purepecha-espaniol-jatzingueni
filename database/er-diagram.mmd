%% ============================================================================
%% J'atzingueni Corpus Database - Entity Relationship Diagram (Mermaid)
%% ============================================================================
%% This diagram represents the complete database schema for the
%% Pur√©pecha-Spanish parallel corpus with support for:
%% - Morphological annotations (agglutinative features)
%% - Automated and manual workflows
%% - Quality metrics tracking
%% - Dialectal variation (PostGIS)
%% ============================================================================

erDiagram
    %% ========================================================================
    %% CORE ENTITIES: Sources and Documents
    %% ========================================================================
    
    source ||--o{ document : "contains"
    source {
        bigint id PK "GENERATED ALWAYS AS IDENTITY"
        varchar(512) name 
        varchar(512) author
        varchar(256) publisher
        varchar(128) licence
        text url
        timestamp created_at
        timestamp updated_at
    }
    
    document_group {
        bigint id PK "GENERATED ALWAYS AS IDENTITY"
        varchar name "e. g. The Bible: Jehova Witnesses Edition"
        text description
        jsonb metadata
        timestamp created_at
        timestamp updated_at
    }

    document_group ||--o{ document : "includes"
    document {
        bigint id PK "GENERATED ALWAYS AS IDENTITY"
        bigint source_id FK
        varchar title "e. g. The Bible New International Version"
        enum genre "religious, educational, conversational, narrative"
        enum lang "tsz, es, en"
        enum tsz_dialect "Values: lacustre, central, serrana. NULL if lang!=tsz"
        %% TODO: expand metadata in its own columns
        jsonb metadata

        text raw_text "Original document text, unmodified"
        text full_text "Full document text, formatted to be ready to take sample for training"
        tsvector text_vector "Optimization for thematic full-text search"
        double quality "Fuzzy number between 0 and 1"

        bigint document_group_id FK "Group of parallel documents"

        timestamp created_at
        timestamp updated_at
    }
    
    %% ========================================================================
    %% SENTENCES: Core linguistic data
    %% ========================================================================
    
    document ||--o{ sentence : "contains"
    sentence {
        bigint id PK "GENERATED ALWAYS AS IDENTITY"
        bigint document_id FK
        integer index
        enum lang "tsz, es, en; the specific language of a sentence"
        enum tsz_dialect "Values: lacustre, central, serrana. NULL if lang!=tsz"
        jsonb tsz_dialectal_features
        text string "string ready to be used in models"
        %% TODO: Is this tsvector really useful?
        tsvector text_vec "Optimization for thematic search within sentences"

        geometry collection_location "PostGIS point"
        jsonb metadata
        double quality "Fuzzy number between 0 and 1"

        timestamp created_at
        timestamp updated_at
    }
    
    %% ========================================================================
    %% ALIGNMENTS: Sentence pair alignments
    %% ========================================================================
    
    sentence ||--o{ alignment : "tsz_sentence"
    sentence ||--o{ alignment : "es_sentence"
    alignment ||--o| alignment : "parent_correction"
    alignment {
        bigint id PK "GENERATED ALWAYS AS IDENTITY"
        bigint tsz_sentence_id FK
        bigint es_sentence_id FK
        enum alignment_method "fast_align, awesome_align, manual"
        decimal alignment_score "0-1 confidence"
        enum quality_status "auto_aligned, reviewed, validated"
        jsonb word_alignments "Word-level data"
        varchar corrected_by "User who corrected"
        text correction_notes
        integer version "Version control"
        bigint parent_alignment_id FK "Previous version"
        timestamp created_at
        timestamp updated_at
    }
    
    %% ========================================================================
    %% MORPHOLOGICAL ANNOTATIONS: Token-level analysis
    %% ========================================================================

    sentence ||--o{ morphological_annotation : "has"
    morphological_annotation {
        bigint id PK "GENERATED ALWAYS AS IDENTITY"
        bigint sentence_id FK
        integer token_index "Position in sentence"
        text token "Surface form"
        text[] morphemes "Decomposed morphemes"
        text[] morpheme_glosses "Glosses"
        text[] morpheme_types "root, affix, suffix"
        varchar pos_tag "Part of speech"
        varchar upos "Universal POS"
        jsonb features "Morphological features"
        varchar annotation_method "automatic, manual"
        varchar annotator
        decimal confidence_score
        timestamp created_at
        timestamp updated_at
    }
    %% TODO: include syntactic annotations too!

%% NOTE from Aaron-Uriel: I think we shouldn't focus on the next entities just
%%                        for now. These entities will be more useful if we
%%                        have a working developing plantform for real users.


    %% ========================================================================
    %% QUALITY METRICS: Pipeline and alignment quality
    %% ========================================================================
    
    pipeline_run ||--o{ alignment_quality_metric : "produces"
    alignment ||--o{ alignment_quality_metric : "measured_by"

    pipeline_run {
        bigint id PK "GENERATED ALWAYS AS IDENTITY"
        varchar name
        varchar pipeline_type "collection, alignment, export"
        jsonb configuration "Pipeline parameters"
        timestamp started_at
        timestamp completed_at
        varchar status "running, completed, failed"
        text error_message
        integer items_processed
        integer items_succeeded
        integer items_failed
        jsonb metadata
    }
    
    alignment_quality_metric {
        bigint id PK "GENERATED ALWAYS AS IDENTITY"
        bigint alignment_id FK
        bigint pipeline_run_id FK
        decimal alignment_accuracy "PRIMARY METRIC"
        decimal bleu_score "Secondary metric"
        decimal ter_score "Translation Error Rate"
        decimal length_ratio
        integer corpus_size_tokens
        integer vocabulary_size
        decimal oov_rate "Out-of-vocabulary"
        integer processing_time_ms
        jsonb metrics_data "Additional metrics"
        timestamp computed_at
    }
    
    corpus_statistic {
        bigint id PK "GENERATED ALWAYS AS IDENTITY"
        timestamp computed_at
        integer total_sentence_pairs
        integer tsz_sentences
        integer es_sentences
        integer auto_aligned_count
        integer manually_reviewed_count
        integer validated_count
        decimal avg_alignment_accuracy
        decimal avg_alignment_score
        integer total_tsz_tokens
        integer total_es_tokens
        integer tsz_vocabulary_size
        integer es_vocabulary_size
        jsonb coverage_by_source "Distribution by source"
        jsonb dialect_distribution "Dialectal statistics"
        jsonb additional_stats
    }
    
    %% ========================================================================
    %% MANUAL ANNOTATION WORKFLOW: Human-in-the-loop
    %% ========================================================================
    
    annotation_task ||--o{ annotation_decision : "contains"
    
    annotation_task {
        bigint id PK "GENERATED ALWAYS AS IDENTITY"
        varchar type "alignment_review, morphology"
        varchar assigned_to "User/annotator"
        integer priority "1-10 urgency"
        jsonb target_items "Items to review"
        varchar status "pending, in_progress, completed"
        integer progress "Percentage"
        timestamp created_at
        timestamp started_at
        timestamp completed_at
        text notes
        jsonb metadata
    }
    
    annotation_decision {
        bigint id PK "GENERATED ALWAYS AS IDENTITY"
        bigint task_id FK
        varchar entity_type "sentence, alignment, morphology"
        bigint entity_id "Reference to entity"
        varchar decision_type "accept, reject, correct"
        jsonb previous_value
        jsonb new_value
        varchar annotator
        integer confidence "1-5 scale"
        text notes
        timestamp created_at
    }
    
    %% ========================================================================
    %% EXPORT: Data interoperability
    %% ========================================================================

    export_job {
        bigint id PK "GENERATED ALWAYS AS IDENTITY"
        varchar format "tmx, conllu, json, pytorch"
        jsonb filter_criteria "What to export"
        text output_path
        bigint file_size_bytes
        varchar status "pending, running, completed"
        timestamp started_at
        timestamp completed_at
        integer records_exported
        jsonb metadata
    }
